{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "glove_GRU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icNlOrUPs7xp"
      },
      "source": [
        "We'll first try with the simplest possible approach based on char-RNN that read all the excerpt and predicts in output the target complexity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RoiZuW4l1Ed",
        "outputId": "f04cc625-720b-4945-ceb1-a38bc4dd5829"
      },
      "source": [
        "!pip install torchtext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAIyrp5Fs7xt",
        "outputId": "6d19b74b-12d8-4a4b-d3bf-c863ca598166"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"{device} is used\")\n",
        "\n",
        "# seed everything\n",
        "seed = 1\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONASSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "#os.environ['WANDB_CONSOLE'] = 'off'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXcYbQg6mYOe",
        "outputId": "ed1c339e-5a8f-497b-f8c7-0e6f9ecbb17a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAk8BRNKs7xv",
        "outputId": "28484f14-20dc-45fe-fec7-0bb7ebea3eaa"
      },
      "source": [
        "# Read the data\n",
        "# Internal datasets\n",
        "training = pd.read_csv('/content/drive/MyDrive/Unipi/HLT/HLT-Project/internal_train.csv').to_numpy()\n",
        "test = pd.read_csv('/content/drive/MyDrive/Unipi/HLT/HLT-Project/internal_test.csv').to_numpy()\n",
        "# Real datasets (Keep only these ones for kaggle (delete test))\n",
        "blind_test = pd.read_csv('/content/drive/MyDrive/Unipi/HLT/HLT-Project/test.csv').to_numpy()\n",
        "full_training = pd.read_csv('/content/drive/MyDrive/Unipi/HLT/HLT-Project/train.csv').to_numpy()\n",
        "\n",
        "# TODO: Remove to train on full dataset\n",
        "#training = training[:10, :]\n",
        "\n",
        "training = np.random.permutation(training)\n",
        "print(training.shape, test.shape, blind_test.shape, full_training.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2434, 6) (400, 6) (7, 4) (2834, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIYcHII9s7xv",
        "outputId": "aab5ef5f-cfdc-474c-aa12-20c5ba2020c9"
      },
      "source": [
        "# id,url_legal,license,excerpt,target,standard_error\n",
        "\n",
        "# We have 5 features (id,url_legal,license,excerpt,standard_error) and 1 output 'target'\n",
        "\n",
        "# For our model we'll only use the excerpt as a feature\n",
        "training_X = training[:, 3]\n",
        "training_Y = training[:, 4]\n",
        "print('training shape =', training_X.shape, training_Y.shape)\n",
        "\n",
        "full_training_X = full_training[:, 3]\n",
        "full_training_Y = full_training[:, 4]\n",
        "print('Real training shape =', full_training_X.shape, full_training_Y.shape)\n",
        "\n",
        "test_X = test[:, 3]\n",
        "test_Y = test[:, 4]\n",
        "print('test shape =', test_X.shape, test_Y.shape)\n",
        "\n",
        "blind_test_X = blind_test[:, 3]\n",
        "print('BLIND test shape =', blind_test_X.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training shape = (2434,) (2434,)\n",
            "Real training shape = (2834,) (2834,)\n",
            "test shape = (400,) (400,)\n",
            "BLIND test shape = (7,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi8sdh8qs7xw",
        "outputId": "5e66e0a4-c50d-4fe1-a7fb-a283a485429b"
      },
      "source": [
        "print(training_X[0])\n",
        "print('\\nTarget =', training_Y[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have found that when I used blood charcoal or bone coal in place of wood coal it was still more efficient; but it must be mentioned that when they are used they must be purified as follows before using: Charcoal from blood contains potash and hence it is necessary to wash it with distilled water and dry it before using it. Bone coal (also called bone black, animal charcoal, etc.) contains on an average 10 per cent. of nitrogenous and hydrogenated carbon, 8 per cent. of carbonate of lime, 78 per cent. of phosphate of lime, besides phosphate of magnesia, sulphate of lime, soluble salts, etc. Before using, it should be treated with dilute hydrochloric acid until it does not effervesce any more. The bone coal is then left to stand for 24 or 30 hours and at the end of this time is washed with distilled water until the wash water no longer reddens a blue piece of litmus paper, i.e., until every trace of hydrochloric acid has been removed from the bone coal. Wood charcoal may be treated in like manner.\n",
            "\n",
            "Target = -2.308546397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh-F3FJjs7xy"
      },
      "source": [
        "### Turning excerpts into Tensors\n",
        "\n",
        "Map each word to the its glove embeddings ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHwGRXqT1-d_",
        "outputId": "4feb6774-f861-4f54-f95b-8bf500a73807"
      },
      "source": [
        "import re\n",
        "from torchtext.legacy import data, datasets, vocab\n",
        "\n",
        "embedding_dim = 300\n",
        "glove = GloVe(name=\"840B\", dim=embedding_dim)\n",
        "\n",
        "# Turn a line of words into the curresponding indices\n",
        "def lineToTensor(line):\n",
        "    # Split a string into array of words and punctation\n",
        "    # \"Much, fun.\" => [\"Much\", \",\", \"fun\", \".\"]\n",
        "    words = re.findall(r\"[\\w']+|[.,!?;]\", line)\n",
        "    tensor = torch.tensor([glove.stoi[w] for w in words if w in glove.stoi], dtype=torch.long)\n",
        "    return tensor\n",
        "\n",
        "print(lineToTensor(training_X[0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.840B.300d.zip: 2.18GB [06:51, 5.29MB/s]                            \n",
            "100%|█████████▉| 2195162/2196017 [03:42<00:00, 10370.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([    12,     31,    254,     15,     82,     12,    183,   1231,  19259,\n",
            "            32,   4868,   7604,      7,    246,      5,   2179,   7604,     21,\n",
            "            30,    194,     50,   3239,     54,     42,     21,    265,     26,\n",
            "          1880,     15,     82,     49,     23,    183,     49,    265,     26,\n",
            "         26823,     28,   3186,    182,    245,  22786,     29,   1231,   1795,\n",
            "         88291,      3,   6759,     21,     10,   1222,      4,   5003,     21,\n",
            "            19,  29893,    333,      3,   2065,     21,    182,    245,     21,\n",
            "             1,  10812,   7604,     89,    416,   4868,    536,      0,   2479,\n",
            "         19259,      0,   2605,      1,   1795,     17,     39,   1149,    167,\n",
            "           404,   4018,      1,      5, 194722,      3,  64460,   4052,      0,\n",
            "           236,    404,   4018,      1,      5,  33234,      5,  12209,      0,\n",
            "          4795,    404,   4018,      1,      5,  27451,      5,  12209,      0,\n",
            "          6139,  27451,      5, 183295,      0,  70949,      5,  12209,      0,\n",
            "         24800,  22447,      0,   2605,      1,   2103,    245,      0,     21,\n",
            "           139,     26,   2926,     19,  38554,  77692,   3689,    355,     21,\n",
            "           154,     35, 766741,     97,     50,      1,     22,   4868,   7604,\n",
            "            10,    123,    331,      4,   1333,     11,    418,     32,    307,\n",
            "           419,      3,     25,      2,    283,      5,     27,     77,     10,\n",
            "          9734,     19,  29893,    333,    355,      2,   5003,    333,     96,\n",
            "           843, 516258,      6,   1394,   1104,      5,  74455,    872,      0,\n",
            "           108,      1,   1939,      1,      0,    355,    230,   9347,      5,\n",
            "         77692,   3689,     45,     84,   2471,     29,      2,   4868,   7604,\n",
            "             1,   3121,  19259,    119,     26,   2926,      7,     64,   2707,\n",
            "             1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s8cf7iTs7xz",
        "outputId": "6f579d28-e7e4-44dd-e896-52865bb134b2"
      },
      "source": [
        "# We want the entire dataset encoded with the glove embeddings\n",
        "# So, the final size will be (n_samples, 1, excerpt_length, embedding_dim) (extra dimension 1 inserted for pytorch batch)\n",
        "# Since a tensor has fixed size we pad the sequences to ensure all have the same length.\n",
        "\n",
        "# Get the max excerpt length and encode the training set\n",
        "max_excerpt_len = len(max(training_X, key=len))\n",
        "enc_training_X = np.zeros((training_X.shape[0], 1, max_excerpt_len,))\n",
        "training_lengths = []\n",
        "for i, x in enumerate(training_X):\n",
        "    enc_x = lineToTensor(x)\n",
        "    enc_training_X[i, 0, :enc_x.shape[0]] = enc_x\n",
        "    training_lengths.append(enc_x.shape[0])\n",
        "\n",
        "print('encoded Training shape =',enc_training_X.shape)\n",
        "\n",
        "\n",
        "max_excerpt_len = len(max(full_training_X, key=len))\n",
        "enc_full_training_X = np.zeros((full_training_X.shape[0], 1, max_excerpt_len,))\n",
        "full_training_lengths = []\n",
        "for i, x in enumerate(full_training_X):\n",
        "    enc_x = lineToTensor(x)\n",
        "    enc_full_training_X[i, 0, :enc_x.shape[0]] = enc_x\n",
        "    full_training_lengths.append(enc_x.shape[0])\n",
        "\n",
        "print('encoded Real/Full Training shape =',enc_full_training_X.shape)\n",
        "\n",
        "\n",
        "max_excerpt_len = len(max(test_X, key=len))\n",
        "enc_test_X = np.zeros((test_X.shape[0], 1, max_excerpt_len,))\n",
        "test_lengths = []\n",
        "for i, x in enumerate(test_X):\n",
        "    enc_x = lineToTensor(x)\n",
        "    enc_test_X[i, 0, :enc_x.shape[0]] = enc_x\n",
        "    test_lengths.append(enc_x.shape[0])\n",
        "\n",
        "print('enc. Test shape =', enc_test_X.shape)\n",
        "\n",
        "\n",
        "max_excerpt_len = len(max(blind_test_X, key=len))\n",
        "enc_blind_test_X = np.zeros((blind_test_X.shape[0], 1, max_excerpt_len,))\n",
        "blind_test_lengths = []\n",
        "for i, x in enumerate(blind_test_X):\n",
        "    enc_x = lineToTensor(x)\n",
        "    enc_blind_test_X[i, 0, :enc_x.shape[0]] = enc_x\n",
        "    blind_test_lengths.append(enc_x.shape[0])\n",
        "\n",
        "print('enc. Test shape =', enc_blind_test_X.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoded Training shape = (2434, 1, 1341)\n",
            "encoded Real/Full Training shape = (2834, 1, 1341)\n",
            "enc. Test shape = (400, 1, 1323)\n",
            "enc. Test shape = (7, 1, 1144)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKV-nZKJs7x0",
        "outputId": "4c026038-397e-46dd-9a90-74a89017e192"
      },
      "source": [
        "from math import floor\n",
        "#Utility function to get a random sample\n",
        "def randomTrainingExample():\n",
        "    i = np.random.randint(0, training_X.shape[0])\n",
        "    excerpt_tensor = lineToTensor(training_X[i])\n",
        "    target_tensor = torch.tensor(training_Y[i], dtype=torch.float)\n",
        "    return excerpt_tensor, target_tensor\n",
        "\n",
        "randomTrainingExample()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 61946,     99,     31,   3917,     52, 216787,     11,      6,    212,\n",
              "              0,     42,   4090,      3,   4620,    194,     47,     35,    113,\n",
              "            114,    138,     52,     21,      1,    242,     51,   1492,    657,\n",
              "         216787,     41,    192,     99,     32,     68,     21,    406,   2833,\n",
              "          29441,     99,     50,    661,      1,  13831,    510,      4,    702,\n",
              "             50,     52, 216787,     24,   2193,  29441,     99,     52,     58,\n",
              "           2674,      5, 216787,     32,  31521,      0,     32,   8713,   3080,\n",
              "              5,    830,     32,  17965,      4,     26,     64,    458,    639,\n",
              "              1,    148,    549,      0,      6,    377,    291,   6903,     58,\n",
              "          13002,     24,  17965,      4,   1532,      7,      6,    239,    153,\n",
              "             68,     49,     47,     35,    700,      2,   1547,      1,  61946,\n",
              "             99,   1594,     15,     49,  32706,     58,  13002,    145,     49,\n",
              "            157,      4,    111,    476,      3,    498,   4866,     19,     99,\n",
              "              0,      3,    145, 216787,     41,     26,   1704,      4,     92,\n",
              "              1,    605,     99,    291,  32706,     58,  13002,     82,     49,\n",
              "             23,     25,    329,     32,    134,      0,     59,     15,     99,\n",
              "             47,     35,   2625,     92,   7231,      3,     49,     41,   9151,\n",
              "             17,     78,     49,     31,      4,     47,      1,    605,     99,\n",
              "          32706,     58,  13002,     82,     49,    822,     94,     99,      0,\n",
              "             59,     15,     49,     41,    111,      6,    112,   5731,      3,\n",
              "            889,    478,    476,      1,    605,     99,     38,    709, 216787,\n",
              "             82,     49,     86,      4,    113,    458,    114,    133,      0,\n",
              "             68,     49,    137,      2,    377,     38,   2089,     92,    153,\n",
              "             82,     49,   1585,     50,  29441,      1]), tensor(-0.5144))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxgzMVEws7x0"
      },
      "source": [
        "class CommonLitDataset(Dataset):\n",
        "    # X: numpy matrix (n_samples, 1, excerpt_length, embedding_dim)\n",
        "    def __init__(self, X, Y, lengths):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.lengths = lengths\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (glove.vectors[self.X[idx][0]].float(), self.lengths[idx]), torch.tensor(self.Y[idx]).float()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLjCYgNls7x0"
      },
      "source": [
        "# Define the model\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(GRU, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=3, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x, sequence_length):\n",
        "        x_pack = pack_padded_sequence(x, sequence_length, batch_first=True, enforce_sorted=False)\n",
        "        lstm_out, ht = self.gru(x_pack)\n",
        "        return self.linear(ht[-1])\n",
        "\n",
        "    def initHidden(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.hidden_dim), torch.zeros(1, batch_size, self.hidden_dim))\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbzD09zHqmfF"
      },
      "source": [
        "def compute_mse(model, generator):\n",
        "    model.eval()\n",
        "    mse = 0.0\n",
        "    error = nn.MSELoss(reduction='sum')\n",
        "    n = 0\n",
        "    for (x, seq_len), y in generator:\n",
        "        x, targets_batch = x.to(device), y.to(device)\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        n += batch_size\n",
        "\n",
        "        output = model(x, seq_len)\n",
        "\n",
        "        targets_batch = torch.reshape(targets_batch, (batch_size, 1))\n",
        "\n",
        "        loss = error(output, targets_batch)\n",
        "        mse += loss.item()\n",
        "    return mse / n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "WNTcVkpes7x2",
        "outputId": "12646d89-b836-4775-e939-706b7d83f357"
      },
      "source": [
        "import time\n",
        "from math import floor, inf\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "start = time.time()\n",
        "print_every = 1\n",
        "plot_every = 1\n",
        "\n",
        "\n",
        "BATCH_SIZE = 16     # batch = 16\n",
        "hidden_dim = 256    # 256\n",
        "epochs = 150          # 75\n",
        "lr = 0.00003         # 0.00005\n",
        "weight_decay = 1e-8 # 1e-7\n",
        "\n",
        "# test_error = 0.61\n",
        "\n",
        "gru = GRU(hidden_dim).to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "parameters = filter(lambda p: p.requires_grad, gru.parameters())\n",
        "optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "params = {'batch_size': BATCH_SIZE,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "\n",
        "commonlit_dataset1 = CommonLitDataset(enc_training_X[400:], training_Y[400:], training_lengths[400:])\n",
        "training_generator = torch.utils.data.DataLoader(commonlit_dataset1, **params)\n",
        "\n",
        "commonlit_dataset2 = CommonLitDataset(enc_training_X[:400], training_Y[:400], training_lengths[:400])\n",
        "validation_generator = torch.utils.data.DataLoader(commonlit_dataset2, **params)\n",
        "\n",
        "# Early stopping logic\n",
        "val_losses = []\n",
        "best_val_error = inf\n",
        "best_val_epoch = 0\n",
        "\n",
        "for iter in range(1, epochs + 1):\n",
        "    total = 0\n",
        "    current_loss = 0.0\n",
        "    gru.train()\n",
        "    for (x, seq_len), y in training_generator:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = gru(x, seq_len)\n",
        "\n",
        "        loss = criterion(y_pred, y.unsqueeze(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*y.shape[0]\n",
        "        total += y.shape[0]\n",
        "\n",
        "    # Mean squared error\n",
        "    current_loss /= total\n",
        "\n",
        "    current_val_error = compute_mse(gru, validation_generator)\n",
        "    val_losses.append(current_val_error)\n",
        "    if current_val_error < best_val_error:\n",
        "        best_val_error = current_val_error\n",
        "        best_val_epoch = iter\n",
        "\n",
        "    # Print iter number, loss\n",
        "    if iter % print_every == 0:\n",
        "        print('Iteration %d | %d%% (%s) MSE = %.4f Val MSE = %.4f' % (iter, iter / epochs * 100, timeSince(start), current_loss, current_val_error))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 | 0% (0m 7s) MSE = 1.8350 Val MSE = 1.8815\n",
            "Iteration 2 | 1% (0m 13s) MSE = 1.7498 Val MSE = 1.7034\n",
            "Iteration 3 | 2% (0m 19s) MSE = 1.4681 Val MSE = 1.3694\n",
            "Iteration 4 | 2% (0m 26s) MSE = 1.2116 Val MSE = 1.1607\n",
            "Iteration 5 | 3% (0m 32s) MSE = 1.0930 Val MSE = 1.0967\n",
            "Iteration 6 | 4% (0m 38s) MSE = 1.0689 Val MSE = 1.0869\n",
            "Iteration 7 | 4% (0m 44s) MSE = 1.0669 Val MSE = 1.0855\n",
            "Iteration 8 | 5% (0m 51s) MSE = 1.0668 Val MSE = 1.0858\n",
            "Iteration 9 | 6% (0m 57s) MSE = 1.0669 Val MSE = 1.0857\n",
            "Iteration 10 | 6% (1m 4s) MSE = 1.0670 Val MSE = 1.0859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-091ad0668bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-3e758ee12331>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sequence_length)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_layer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 841\u001b[0;31m                              self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    842\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "7CE1fwNJs7x2",
        "outputId": "2a980543-eb54-4bdb-ec94-ae45a9bae485"
      },
      "source": [
        "# Plot the learning curve\n",
        "plt.figure()\n",
        "plt.plot(all_losses, label='Training error')\n",
        "plt.plot(val_losses, label='Val Error')\n",
        "plt.legend()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f668347da10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP1AJH_32H1V"
      },
      "source": [
        "## Retrain the model on the full train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lCC0Tlv2Hld",
        "outputId": "e8c39a0f-e9f8-41b1-c3c6-b4328fdf05e1"
      },
      "source": [
        "params = {'batch_size': BATCH_SIZE,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "\n",
        "commonlit_dataset3 = CommonLitDataset(enc_full_training_X, full_training_Y, full_training_lengths)\n",
        "full_training_generator = torch.utils.data.DataLoader(commonlit_dataset3, **params)\n",
        "\n",
        "final_model = GRU(hidden_dim).to(device)\n",
        "\n",
        "epochs = best_val_epoch\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "parameters = filter(lambda p: p.requires_grad, final_model.parameters())\n",
        "optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "\n",
        "for iter in range(1, epochs + 1):\n",
        "    total = 0\n",
        "    current_loss = 0.0\n",
        "    final_model.train()\n",
        "    for (x, seq_len), y in training_generator: # TODO: Change in full_training_generator (to include the test data)\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = final_model(x, seq_len)\n",
        "\n",
        "        loss = criterion(y_pred, y.unsqueeze(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*y.shape[0]\n",
        "        total += y.shape[0]\n",
        "\n",
        "    # Mean squared error\n",
        "    current_loss /= total\n",
        "\n",
        "    # Print iter number, loss\n",
        "    if iter % print_every == 0:\n",
        "        print('Iteration %d | %d%% (%s) MSE = %.4f' % (iter, iter / epochs * 100, timeSince(start), current_loss))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 | 7% (0m 8s) MSE = 1.1108\n",
            "Iteration 2 | 14% (0m 17s) MSE = 0.8441\n",
            "Iteration 3 | 21% (0m 26s) MSE = 0.6629\n",
            "Iteration 4 | 28% (0m 35s) MSE = 0.5666\n",
            "Iteration 5 | 35% (0m 44s) MSE = 0.5133\n",
            "Iteration 6 | 42% (0m 53s) MSE = 0.4574\n",
            "Iteration 7 | 50% (1m 2s) MSE = 0.4369\n",
            "Iteration 8 | 57% (1m 11s) MSE = 0.4045\n",
            "Iteration 9 | 64% (1m 20s) MSE = 0.3625\n",
            "Iteration 10 | 71% (1m 32s) MSE = 0.3463\n",
            "Iteration 11 | 78% (1m 41s) MSE = 0.3447\n",
            "Iteration 12 | 85% (1m 50s) MSE = 0.3287\n",
            "Iteration 13 | 92% (1m 59s) MSE = 0.3217\n",
            "Iteration 14 | 100% (2m 8s) MSE = 0.3162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "2Ek2Bi2P8cDS",
        "outputId": "5ca66226-02a8-4164-8d6f-66708720798f"
      },
      "source": [
        "# Plot the learning curve\n",
        "plt.figure()\n",
        "plt.plot(all_losses, label='Training error')\n",
        "plt.legend()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6682f39310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1eFoTOT6Ajx"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3odVoUa5rXI"
      },
      "source": [
        "test_params = {'batch_size': 64,\n",
        "          'shuffle': False,\n",
        "          'num_workers': 0}\n",
        "\n",
        "internal_test_dataset = CommonLitDataset(enc_test_X, test_Y, test_lengths)\n",
        "test_generator = torch.utils.data.DataLoader(internal_test_dataset, **test_params)\n",
        "\n",
        "\n",
        "blind_test_params = {'batch_size': 1,\n",
        "          'shuffle': False,\n",
        "          'num_workers': 0}\n",
        "\n",
        "blind_test_dataset = CommonLitDataset(enc_blind_test_X, np.zeros(enc_blind_test_X.shape), blind_test_lengths)\n",
        "blind_test_generator = torch.utils.data.DataLoader(blind_test_dataset, **blind_test_params)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSz_-_y_s7x3",
        "outputId": "0c39de1c-6fa9-4100-82ce-75d2185b962b"
      },
      "source": [
        "# Compute the final MSE on the training set\n",
        "def compute_squared_error(generator):\n",
        "    error = nn.MSELoss(reduction='sum')\n",
        "    with torch.no_grad():\n",
        "        mse = 0.0\n",
        "        for (x, seq_len), targets_batch in generator:\n",
        "            x, targets_batch = x.to(device), targets_batch.to(device)\n",
        "\n",
        "            batch_size = x.shape[0]\n",
        "\n",
        "            output = final_model(x, seq_len)\n",
        "\n",
        "            targets_batch = torch.reshape(targets_batch, (batch_size, 1))\n",
        "\n",
        "            loss = error(output, targets_batch)\n",
        "            mse += loss.item()\n",
        "    return mse\n",
        "print('Training RMSE =', np.sqrt(compute_squared_error(training_generator) / enc_training_X.shape[0]))\n",
        "# A bit useless since we train also on this data\n",
        "print('Internal TEST RMSE =', np.sqrt(compute_squared_error(test_generator) / enc_test_X.shape[0]))\n",
        "    "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training RMSE = 0.4943330085804977\n",
            "Internal TEST RMSE = 0.6446025702580013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGPYFMTABCmK"
      },
      "source": [
        "# Compute blind test set outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wnMzcZvCl8Z",
        "outputId": "97ebd72d-a557-4078-af38-83da233e0e76"
      },
      "source": [
        "outputs = []\n",
        "with torch.no_grad():\n",
        "    for i, ((x, seq_len), targets_batch) in enumerate(blind_test_generator):\n",
        "        excerpts_batch = x.to(device)\n",
        "\n",
        "        batch_size = excerpts_batch.shape[0]\n",
        "\n",
        "        output = final_model(excerpts_batch, seq_len)\n",
        "        id = blind_test[i, 0]\n",
        "        print(id, output.item())\n",
        "        outputs.append((id, output.item()))\n",
        "\n",
        "# Save outputs to submission.csv\n",
        "if False:\n",
        "    with open('submission.csv', 'w') as f:\n",
        "        f.write('id,target\\n')\n",
        "        for id, o in outputs:\n",
        "            f.write(id+','+str(o)+'\\n')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c0f722661 -1.3720139265060425\n",
            "f0953f0a5 -0.1726866364479065\n",
            "0df072751 -0.22537215054035187\n",
            "04caf4e0c -2.459099769592285\n",
            "0e63f8bea -1.8731929063796997\n",
            "12537fe78 -1.6504805088043213\n",
            "965e592c0 0.11292542517185211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP4t2r6es7x4"
      },
      "source": [
        " NEXT:\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        " \n",
        " \n",
        " \n",
        "    Try the nn.LSTM and nn.GRU layers\n",
        "    Combine multiple of these RNNs as a higher level network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt08ZXlQ5gvI"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}