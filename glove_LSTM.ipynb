{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "glove_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icNlOrUPs7xp"
      },
      "source": [
        "We'll first try with the simplest possible approach based on char-RNN that read all the excerpt and predicts in output the target complexity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RoiZuW4l1Ed",
        "outputId": "643e9b59-a4db-4480-a282-225665e8a040"
      },
      "source": [
        "!pip install torchtext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAIyrp5Fs7xt",
        "outputId": "2de12649-7d27-49c5-f640-57c41d8076e9"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"{device} is used\")\n",
        "\n",
        "# seed everything\n",
        "seed = 1\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONASSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "#os.environ['WANDB_CONSOLE'] = 'off'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXcYbQg6mYOe",
        "outputId": "55755a8d-46df-48e4-a8df-cf49f4857a8d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAk8BRNKs7xv",
        "outputId": "08a14aa1-1438-497c-8597-bb9667cd430f"
      },
      "source": [
        "# Read the data\n",
        "# Internal datasets\n",
        "training = pd.read_csv('/content/drive/MyDrive/Unipi/HLT/HLT-Project/internal_train.csv').to_numpy()\n",
        "test = pd.read_csv('/content/drive/MyDrive/Unipi/HLT/HLT-Project/internal_test.csv').to_numpy()\n",
        "# Real datasets (Keep only these ones for kaggle (delete test))\n",
        "blind_test = pd.read_csv('/content/drive/MyDrive/Unipi/HLT/HLT-Project/test.csv').to_numpy()\n",
        "full_training = pd.read_csv('/content/drive/MyDrive/Unipi/HLT/HLT-Project/train.csv').to_numpy()\n",
        "\n",
        "# TODO: Remove to train on full dataset\n",
        "#training = training[:10, :]\n",
        "\n",
        "training = np.random.permutation(training)\n",
        "print(training.shape, test.shape, blind_test.shape, full_training.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2434, 6) (400, 6) (7, 4) (2834, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIYcHII9s7xv",
        "outputId": "d124158f-3b51-420e-e804-d811bed8537f"
      },
      "source": [
        "# id,url_legal,license,excerpt,target,standard_error\n",
        "\n",
        "# We have 5 features (id,url_legal,license,excerpt,standard_error) and 1 output 'target'\n",
        "\n",
        "# For our model we'll only use the excerpt as a feature\n",
        "training_X = training[:, 3]\n",
        "training_Y = training[:, 4]\n",
        "print('training shape =', training_X.shape, training_Y.shape)\n",
        "\n",
        "full_training_X = full_training[:, 3]\n",
        "full_training_Y = full_training[:, 4]\n",
        "print('Real training shape =', full_training_X.shape, full_training_Y.shape)\n",
        "\n",
        "test_X = test[:, 3]\n",
        "test_Y = test[:, 4]\n",
        "print('test shape =', test_X.shape, test_Y.shape)\n",
        "\n",
        "blind_test_X = blind_test[:, 3]\n",
        "print('BLIND test shape =', blind_test_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training shape = (2434,) (2434,)\n",
            "Real training shape = (2834,) (2834,)\n",
            "test shape = (400,) (400,)\n",
            "BLIND test shape = (7,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi8sdh8qs7xw",
        "outputId": "19d33027-7684-40ea-f9bf-d5485df338a1"
      },
      "source": [
        "print(training_X[0])\n",
        "print('\\nTarget =', training_Y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have found that when I used blood charcoal or bone coal in place of wood coal it was still more efficient; but it must be mentioned that when they are used they must be purified as follows before using: Charcoal from blood contains potash and hence it is necessary to wash it with distilled water and dry it before using it. Bone coal (also called bone black, animal charcoal, etc.) contains on an average 10 per cent. of nitrogenous and hydrogenated carbon, 8 per cent. of carbonate of lime, 78 per cent. of phosphate of lime, besides phosphate of magnesia, sulphate of lime, soluble salts, etc. Before using, it should be treated with dilute hydrochloric acid until it does not effervesce any more. The bone coal is then left to stand for 24 or 30 hours and at the end of this time is washed with distilled water until the wash water no longer reddens a blue piece of litmus paper, i.e., until every trace of hydrochloric acid has been removed from the bone coal. Wood charcoal may be treated in like manner.\n",
            "\n",
            "Target = -2.308546397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh-F3FJjs7xy"
      },
      "source": [
        "### Turning excerpts into Tensors\n",
        "\n",
        "Map each word to the its glove embeddings ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHwGRXqT1-d_",
        "outputId": "0c6b734b-17ab-422d-b385-4e43a9ec5881"
      },
      "source": [
        "import re\n",
        "from torchtext.legacy import data, datasets, vocab\n",
        "\n",
        "embedding_dim = 300\n",
        "glove = GloVe(name=\"840B\", dim=embedding_dim)\n",
        "\n",
        "# Turn a line of words into the curresponding indices\n",
        "def lineToTensor(line):\n",
        "    # Split a string into array of words and punctation\n",
        "    # \"Much, fun.\" => [\"Much\", \",\", \"fun\", \".\"]\n",
        "    words = re.findall(r\"[\\w']+|[.,!?;]\", line)\n",
        "    tensor = torch.tensor([glove.stoi[w] for w in words if w in glove.stoi], dtype=torch.long)\n",
        "    return tensor\n",
        "\n",
        "print(lineToTensor(training_X[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([    12,     31,    254,     15,     82,     12,    183,   1231,  19259,\n",
            "            32,   4868,   7604,      7,    246,      5,   2179,   7604,     21,\n",
            "            30,    194,     50,   3239,     54,     42,     21,    265,     26,\n",
            "          1880,     15,     82,     49,     23,    183,     49,    265,     26,\n",
            "         26823,     28,   3186,    182,    245,  22786,     29,   1231,   1795,\n",
            "         88291,      3,   6759,     21,     10,   1222,      4,   5003,     21,\n",
            "            19,  29893,    333,      3,   2065,     21,    182,    245,     21,\n",
            "             1,  10812,   7604,     89,    416,   4868,    536,      0,   2479,\n",
            "         19259,      0,   2605,      1,   1795,     17,     39,   1149,    167,\n",
            "           404,   4018,      1,      5, 194722,      3,  64460,   4052,      0,\n",
            "           236,    404,   4018,      1,      5,  33234,      5,  12209,      0,\n",
            "          4795,    404,   4018,      1,      5,  27451,      5,  12209,      0,\n",
            "          6139,  27451,      5, 183295,      0,  70949,      5,  12209,      0,\n",
            "         24800,  22447,      0,   2605,      1,   2103,    245,      0,     21,\n",
            "           139,     26,   2926,     19,  38554,  77692,   3689,    355,     21,\n",
            "           154,     35, 766741,     97,     50,      1,     22,   4868,   7604,\n",
            "            10,    123,    331,      4,   1333,     11,    418,     32,    307,\n",
            "           419,      3,     25,      2,    283,      5,     27,     77,     10,\n",
            "          9734,     19,  29893,    333,    355,      2,   5003,    333,     96,\n",
            "           843, 516258,      6,   1394,   1104,      5,  74455,    872,      0,\n",
            "           108,      1,   1939,      1,      0,    355,    230,   9347,      5,\n",
            "         77692,   3689,     45,     84,   2471,     29,      2,   4868,   7604,\n",
            "             1,   3121,  19259,    119,     26,   2926,      7,     64,   2707,\n",
            "             1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s8cf7iTs7xz",
        "outputId": "51d93e45-9e96-45ec-fbfa-2d1b833a8acb"
      },
      "source": [
        "# We want the entire dataset encoded with the glove embeddings\n",
        "# So, the final size will be (n_samples, 1, excerpt_length, embedding_dim) (extra dimension 1 inserted for pytorch batch)\n",
        "# Since a tensor has fixed size we pad the sequences to ensure all have the same length.\n",
        "\n",
        "# Get the max excerpt length and encode the training set\n",
        "max_excerpt_len = len(max(training_X, key=len))\n",
        "enc_training_X = np.zeros((training_X.shape[0], 1, max_excerpt_len,))\n",
        "training_lengths = []\n",
        "for i, x in enumerate(training_X):\n",
        "    enc_x = lineToTensor(x)\n",
        "    enc_training_X[i, 0, :enc_x.shape[0]] = enc_x\n",
        "    training_lengths.append(enc_x.shape[0])\n",
        "\n",
        "print('encoded Training shape =',enc_training_X.shape)\n",
        "\n",
        "\n",
        "max_excerpt_len = len(max(full_training_X, key=len))\n",
        "enc_full_training_X = np.zeros((full_training_X.shape[0], 1, max_excerpt_len,))\n",
        "full_training_lengths = []\n",
        "for i, x in enumerate(full_training_X):\n",
        "    enc_x = lineToTensor(x)\n",
        "    enc_full_training_X[i, 0, :enc_x.shape[0]] = enc_x\n",
        "    full_training_lengths.append(enc_x.shape[0])\n",
        "\n",
        "print('encoded Real/Full Training shape =',enc_full_training_X.shape)\n",
        "\n",
        "\n",
        "max_excerpt_len = len(max(test_X, key=len))\n",
        "enc_test_X = np.zeros((test_X.shape[0], 1, max_excerpt_len,))\n",
        "test_lengths = []\n",
        "for i, x in enumerate(test_X):\n",
        "    enc_x = lineToTensor(x)\n",
        "    enc_test_X[i, 0, :enc_x.shape[0]] = enc_x\n",
        "    test_lengths.append(enc_x.shape[0])\n",
        "\n",
        "print('enc. Test shape =', enc_test_X.shape)\n",
        "\n",
        "\n",
        "max_excerpt_len = len(max(blind_test_X, key=len))\n",
        "enc_blind_test_X = np.zeros((blind_test_X.shape[0], 1, max_excerpt_len,))\n",
        "blind_test_lengths = []\n",
        "for i, x in enumerate(blind_test_X):\n",
        "    enc_x = lineToTensor(x)\n",
        "    enc_blind_test_X[i, 0, :enc_x.shape[0]] = enc_x\n",
        "    blind_test_lengths.append(enc_x.shape[0])\n",
        "\n",
        "print('enc. Test shape =', enc_blind_test_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoded Training shape = (2434, 1, 1341)\n",
            "encoded Real/Full Training shape = (2834, 1, 1341)\n",
            "enc. Test shape = (400, 1, 1323)\n",
            "enc. Test shape = (7, 1, 1144)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKV-nZKJs7x0",
        "outputId": "2cf97892-8308-45c6-9fe5-84406a723d3f"
      },
      "source": [
        "from math import floor\n",
        "#Utility function to get a random sample\n",
        "def randomTrainingExample():\n",
        "    i = np.random.randint(0, training_X.shape[0])\n",
        "    excerpt_tensor = lineToTensor(training_X[i])\n",
        "    target_tensor = torch.tensor(training_Y[i], dtype=torch.float)\n",
        "    return excerpt_tensor, target_tensor\n",
        "\n",
        "randomTrainingExample()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 61946,     99,     31,   3917,     52, 216787,     11,      6,    212,\n",
              "              0,     42,   4090,      3,   4620,    194,     47,     35,    113,\n",
              "            114,    138,     52,     21,      1,    242,     51,   1492,    657,\n",
              "         216787,     41,    192,     99,     32,     68,     21,    406,   2833,\n",
              "          29441,     99,     50,    661,      1,  13831,    510,      4,    702,\n",
              "             50,     52, 216787,     24,   2193,  29441,     99,     52,     58,\n",
              "           2674,      5, 216787,     32,  31521,      0,     32,   8713,   3080,\n",
              "              5,    830,     32,  17965,      4,     26,     64,    458,    639,\n",
              "              1,    148,    549,      0,      6,    377,    291,   6903,     58,\n",
              "          13002,     24,  17965,      4,   1532,      7,      6,    239,    153,\n",
              "             68,     49,     47,     35,    700,      2,   1547,      1,  61946,\n",
              "             99,   1594,     15,     49,  32706,     58,  13002,    145,     49,\n",
              "            157,      4,    111,    476,      3,    498,   4866,     19,     99,\n",
              "              0,      3,    145, 216787,     41,     26,   1704,      4,     92,\n",
              "              1,    605,     99,    291,  32706,     58,  13002,     82,     49,\n",
              "             23,     25,    329,     32,    134,      0,     59,     15,     99,\n",
              "             47,     35,   2625,     92,   7231,      3,     49,     41,   9151,\n",
              "             17,     78,     49,     31,      4,     47,      1,    605,     99,\n",
              "          32706,     58,  13002,     82,     49,    822,     94,     99,      0,\n",
              "             59,     15,     49,     41,    111,      6,    112,   5731,      3,\n",
              "            889,    478,    476,      1,    605,     99,     38,    709, 216787,\n",
              "             82,     49,     86,      4,    113,    458,    114,    133,      0,\n",
              "             68,     49,    137,      2,    377,     38,   2089,     92,    153,\n",
              "             82,     49,   1585,     50,  29441,      1]), tensor(-0.5144))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxgzMVEws7x0"
      },
      "source": [
        "class CommonLitDataset(Dataset):\n",
        "    # X: numpy matrix (n_samples, 1, excerpt_length, embedding_dim)\n",
        "    def __init__(self, X, Y, lengths):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.lengths = lengths\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (glove.vectors[self.X[idx][0]].float(), self.lengths[idx]), torch.tensor(self.Y[idx]).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLjCYgNls7x0"
      },
      "source": [
        "# Define the model\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        # TODO: Do we also need to pass the cell state in the output layer?\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x, sequence_length):\n",
        "        x_pack = pack_padded_sequence(x, sequence_length, batch_first=True, enforce_sorted=False)\n",
        "        lstm_out, (ht, ct) = self.lstm(x_pack)\n",
        "        return self.linear(ht[-1])\n",
        "\n",
        "    def initHidden(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.hidden_dim), torch.zeros(1, batch_size, self.hidden_dim))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbzD09zHqmfF"
      },
      "source": [
        "def compute_mse(model, generator):\n",
        "    model.eval()\n",
        "    mse = 0.0\n",
        "    error = nn.MSELoss(reduction='sum')\n",
        "    n = 0\n",
        "    for (x, seq_len), y in generator:\n",
        "        x, targets_batch = x.to(device), y.to(device)\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        n += batch_size\n",
        "\n",
        "        output = lstm(x, seq_len)\n",
        "\n",
        "        targets_batch = torch.reshape(targets_batch, (batch_size, 1))\n",
        "\n",
        "        loss = error(output, targets_batch)\n",
        "        mse += loss.item()\n",
        "    return mse / n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNTcVkpes7x2",
        "outputId": "d34b7c2f-fb3e-429e-e273-9286d0dd481a"
      },
      "source": [
        "import time\n",
        "from math import floor, inf\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "start = time.time()\n",
        "print_every = 1\n",
        "plot_every = 1\n",
        "\n",
        "\n",
        "BATCH_SIZE = 16     # batch = 16\n",
        "hidden_dim = 256    # 256\n",
        "epochs = 75         # 50\n",
        "lr = 0.00003         # 0.00005\n",
        "weight_decay = 1e-8 # 1e-7\n",
        "\n",
        "# test_error = 0.66\n",
        "\n",
        "lstm = LSTM(hidden_dim).to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "parameters = filter(lambda p: p.requires_grad, lstm.parameters())\n",
        "optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "params = {'batch_size': BATCH_SIZE,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "\n",
        "commonlit_dataset1 = CommonLitDataset(enc_training_X[400:], training_Y[400:], training_lengths[400:])\n",
        "training_generator = torch.utils.data.DataLoader(commonlit_dataset1, **params)\n",
        "\n",
        "commonlit_dataset2 = CommonLitDataset(enc_training_X[:400], training_Y[:400], training_lengths[:400])\n",
        "validation_generator = torch.utils.data.DataLoader(commonlit_dataset2, **params)\n",
        "\n",
        "# Early stopping logic\n",
        "val_losses = []\n",
        "best_val_error = inf\n",
        "best_val_epoch = 0\n",
        "\n",
        "for iter in range(1, epochs + 1):\n",
        "    total = 0\n",
        "    current_loss = 0.0\n",
        "    lstm.train()\n",
        "    for (x, seq_len), y in training_generator:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = lstm(x, seq_len)\n",
        "\n",
        "        loss = criterion(y_pred, y.unsqueeze(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*y.shape[0]\n",
        "        total += y.shape[0]\n",
        "\n",
        "    # Mean squared error\n",
        "    current_loss /= total\n",
        "\n",
        "    current_val_error = compute_mse(lstm, validation_generator)\n",
        "    val_losses.append(current_val_error)\n",
        "    if current_val_error < best_val_error:\n",
        "        best_val_error = current_val_error\n",
        "        best_val_epoch = iter\n",
        "\n",
        "    # Print iter number, loss\n",
        "    if iter % print_every == 0:\n",
        "        print('Iteration %d | %d%% (%s) MSE = %.4f Val MSE = %.4f' % (iter, iter / epochs * 100, timeSince(start), current_loss, current_val_error))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 | 1% (0m 14s) MSE = 1.3784 Val MSE = 1.1188\n",
            "Iteration 2 | 2% (0m 28s) MSE = 1.0654 Val MSE = 1.0645\n",
            "Iteration 3 | 4% (0m 41s) MSE = 1.0130 Val MSE = 0.9889\n",
            "Iteration 4 | 5% (0m 54s) MSE = 0.8726 Val MSE = 0.7958\n",
            "Iteration 5 | 6% (1m 7s) MSE = 0.7356 Val MSE = 0.7054\n",
            "Iteration 6 | 8% (1m 20s) MSE = 0.6734 Val MSE = 0.6996\n",
            "Iteration 7 | 9% (1m 33s) MSE = 0.6203 Val MSE = 0.6709\n",
            "Iteration 8 | 10% (1m 46s) MSE = 0.6038 Val MSE = 0.6664\n",
            "Iteration 9 | 12% (1m 59s) MSE = 0.6365 Val MSE = 0.7317\n",
            "Iteration 10 | 13% (2m 12s) MSE = 0.5896 Val MSE = 0.6387\n",
            "Iteration 11 | 14% (2m 25s) MSE = 0.5684 Val MSE = 0.6464\n",
            "Iteration 12 | 16% (2m 38s) MSE = 0.5500 Val MSE = 0.6217\n",
            "Iteration 13 | 17% (2m 51s) MSE = 0.5548 Val MSE = 0.6049\n",
            "Iteration 14 | 18% (3m 3s) MSE = 0.5689 Val MSE = 0.6147\n",
            "Iteration 15 | 20% (3m 16s) MSE = 0.5376 Val MSE = 0.6712\n",
            "Iteration 16 | 21% (3m 29s) MSE = 0.5269 Val MSE = 0.5919\n",
            "Iteration 17 | 22% (3m 41s) MSE = 0.5142 Val MSE = 0.6431\n",
            "Iteration 18 | 24% (3m 54s) MSE = 0.5145 Val MSE = 0.5734\n",
            "Iteration 19 | 25% (4m 7s) MSE = 0.5092 Val MSE = 0.5728\n",
            "Iteration 20 | 26% (4m 20s) MSE = 0.5272 Val MSE = 0.5761\n",
            "Iteration 21 | 28% (4m 32s) MSE = 0.4909 Val MSE = 0.5914\n",
            "Iteration 22 | 29% (4m 45s) MSE = 0.4807 Val MSE = 0.5613\n",
            "Iteration 23 | 30% (4m 58s) MSE = 0.4926 Val MSE = 0.6028\n",
            "Iteration 24 | 32% (5m 11s) MSE = 0.4748 Val MSE = 0.5561\n",
            "Iteration 25 | 33% (5m 24s) MSE = 0.4691 Val MSE = 0.5484\n",
            "Iteration 26 | 34% (5m 36s) MSE = 0.4582 Val MSE = 0.5440\n",
            "Iteration 27 | 36% (5m 49s) MSE = 0.4472 Val MSE = 0.5400\n",
            "Iteration 28 | 37% (6m 2s) MSE = 0.4299 Val MSE = 0.5283\n",
            "Iteration 29 | 38% (6m 14s) MSE = 0.4278 Val MSE = 0.5619\n",
            "Iteration 30 | 40% (6m 27s) MSE = 0.4175 Val MSE = 0.4986\n",
            "Iteration 31 | 41% (6m 40s) MSE = 0.4078 Val MSE = 0.5166\n",
            "Iteration 32 | 42% (6m 53s) MSE = 0.4024 Val MSE = 0.4947\n",
            "Iteration 33 | 44% (7m 5s) MSE = 0.4155 Val MSE = 0.4830\n",
            "Iteration 34 | 45% (7m 18s) MSE = 0.3944 Val MSE = 0.4837\n",
            "Iteration 35 | 46% (7m 31s) MSE = 0.3857 Val MSE = 0.5263\n",
            "Iteration 36 | 48% (7m 43s) MSE = 0.3860 Val MSE = 0.4855\n",
            "Iteration 37 | 49% (7m 56s) MSE = 0.3785 Val MSE = 0.4692\n",
            "Iteration 38 | 50% (8m 9s) MSE = 0.3737 Val MSE = 0.4844\n",
            "Iteration 39 | 52% (8m 22s) MSE = 0.3751 Val MSE = 0.4868\n",
            "Iteration 40 | 53% (8m 34s) MSE = 0.3608 Val MSE = 0.5273\n",
            "Iteration 41 | 54% (8m 47s) MSE = 0.3657 Val MSE = 0.4921\n",
            "Iteration 42 | 56% (9m 0s) MSE = 0.3533 Val MSE = 0.4674\n",
            "Iteration 43 | 57% (9m 12s) MSE = 0.3540 Val MSE = 0.4755\n",
            "Iteration 44 | 58% (9m 25s) MSE = 0.3497 Val MSE = 0.4674\n",
            "Iteration 45 | 60% (9m 38s) MSE = 0.3425 Val MSE = 0.4755\n",
            "Iteration 46 | 61% (9m 50s) MSE = 0.3587 Val MSE = 0.5115\n",
            "Iteration 47 | 62% (10m 3s) MSE = 0.3380 Val MSE = 0.4561\n",
            "Iteration 48 | 64% (10m 16s) MSE = 0.3392 Val MSE = 0.4573\n",
            "Iteration 49 | 65% (10m 29s) MSE = 0.3297 Val MSE = 0.4466\n",
            "Iteration 50 | 66% (10m 41s) MSE = 0.3319 Val MSE = 0.4511\n",
            "Iteration 51 | 68% (10m 54s) MSE = 0.3355 Val MSE = 0.4577\n",
            "Iteration 52 | 69% (11m 7s) MSE = 0.3254 Val MSE = 0.4661\n",
            "Iteration 53 | 70% (11m 19s) MSE = 0.3161 Val MSE = 0.4579\n",
            "Iteration 54 | 72% (11m 32s) MSE = 0.3219 Val MSE = 0.4610\n",
            "Iteration 55 | 73% (11m 45s) MSE = 0.3094 Val MSE = 0.4751\n",
            "Iteration 56 | 74% (11m 58s) MSE = 0.3125 Val MSE = 0.4633\n",
            "Iteration 57 | 76% (12m 10s) MSE = 0.3086 Val MSE = 0.4900\n",
            "Iteration 58 | 77% (12m 23s) MSE = 0.3117 Val MSE = 0.4708\n",
            "Iteration 59 | 78% (12m 36s) MSE = 0.3042 Val MSE = 0.4690\n",
            "Iteration 60 | 80% (12m 49s) MSE = 0.2994 Val MSE = 0.4531\n",
            "Iteration 61 | 81% (13m 1s) MSE = 0.3103 Val MSE = 0.5095\n",
            "Iteration 62 | 82% (13m 14s) MSE = 0.3123 Val MSE = 0.4556\n",
            "Iteration 63 | 84% (13m 27s) MSE = 0.2922 Val MSE = 0.4452\n",
            "Iteration 64 | 85% (13m 40s) MSE = 0.2936 Val MSE = 0.4479\n",
            "Iteration 65 | 86% (13m 53s) MSE = 0.2840 Val MSE = 0.4780\n",
            "Iteration 66 | 88% (14m 5s) MSE = 0.2907 Val MSE = 0.4596\n",
            "Iteration 67 | 89% (14m 18s) MSE = 0.2812 Val MSE = 0.4620\n",
            "Iteration 68 | 90% (14m 31s) MSE = 0.2868 Val MSE = 0.5086\n",
            "Iteration 69 | 92% (14m 44s) MSE = 0.2864 Val MSE = 0.4585\n",
            "Iteration 70 | 93% (14m 57s) MSE = 0.2720 Val MSE = 0.4505\n",
            "Iteration 71 | 94% (15m 9s) MSE = 0.2850 Val MSE = 0.5045\n",
            "Iteration 72 | 96% (15m 22s) MSE = 0.2700 Val MSE = 0.4838\n",
            "Iteration 73 | 97% (15m 35s) MSE = 0.2681 Val MSE = 0.4658\n",
            "Iteration 74 | 98% (15m 48s) MSE = 0.2631 Val MSE = 0.5084\n",
            "Iteration 75 | 100% (16m 0s) MSE = 0.2672 Val MSE = 0.4624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "7CE1fwNJs7x2",
        "outputId": "d1bbc1a0-45a2-4323-c4b2-0e5ddcaee2ee"
      },
      "source": [
        "# Plot the learning curve\n",
        "plt.figure()\n",
        "plt.plot(all_losses, label='Training error')\n",
        "plt.plot(val_losses, label='Val Error')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f122dbeef50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP1AJH_32H1V"
      },
      "source": [
        "## Retrain the model on the full train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lCC0Tlv2Hld",
        "outputId": "a9b1b058-db50-4400-bcef-1b709367bbef"
      },
      "source": [
        "params = {'batch_size': BATCH_SIZE,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "\n",
        "commonlit_dataset3 = CommonLitDataset(enc_full_training_X, full_training_Y, full_training_lengths)\n",
        "full_training_generator = torch.utils.data.DataLoader(commonlit_dataset3, **params)\n",
        "\n",
        "final_model = LSTM(hidden_dim).to(device)\n",
        "\n",
        "epochs = best_val_epoch\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "parameters = filter(lambda p: p.requires_grad, final_model.parameters())\n",
        "optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "\n",
        "for iter in range(1, epochs + 1):\n",
        "    total = 0\n",
        "    current_loss = 0.0\n",
        "    final_model.train()\n",
        "    for (x, seq_len), y in training_generator: # TODO: Change in full_training_generator (to include the test data)\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = final_model(x, seq_len)\n",
        "\n",
        "        loss = criterion(y_pred, y.unsqueeze(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*y.shape[0]\n",
        "        total += y.shape[0]\n",
        "\n",
        "    # Mean squared error\n",
        "    current_loss /= total\n",
        "\n",
        "    # Print iter number, loss\n",
        "    if iter % print_every == 0:\n",
        "        print('Iteration %d | %d%% (%s) MSE = %.4f' % (iter, iter / epochs * 100, timeSince(start), current_loss))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 | 1% (0m 11s) MSE = 1.4522\n",
            "Iteration 2 | 3% (0m 23s) MSE = 1.0672\n",
            "Iteration 3 | 4% (0m 35s) MSE = 1.0032\n",
            "Iteration 4 | 6% (0m 46s) MSE = 0.8537\n",
            "Iteration 5 | 7% (0m 58s) MSE = 0.7312\n",
            "Iteration 6 | 9% (1m 10s) MSE = 0.6586\n",
            "Iteration 7 | 11% (1m 21s) MSE = 0.6392\n",
            "Iteration 8 | 12% (1m 33s) MSE = 0.5978\n",
            "Iteration 9 | 14% (1m 45s) MSE = 0.5945\n",
            "Iteration 10 | 15% (1m 56s) MSE = 0.5770\n",
            "Iteration 11 | 17% (2m 8s) MSE = 0.5639\n",
            "Iteration 12 | 19% (2m 20s) MSE = 0.5795\n",
            "Iteration 13 | 20% (2m 31s) MSE = 0.5458\n",
            "Iteration 14 | 22% (2m 43s) MSE = 0.5321\n",
            "Iteration 15 | 23% (2m 55s) MSE = 0.5415\n",
            "Iteration 16 | 25% (3m 6s) MSE = 0.5174\n",
            "Iteration 17 | 26% (3m 18s) MSE = 0.5259\n",
            "Iteration 18 | 28% (3m 30s) MSE = 0.5022\n",
            "Iteration 19 | 30% (3m 41s) MSE = 0.5068\n",
            "Iteration 20 | 31% (3m 53s) MSE = 0.5005\n",
            "Iteration 21 | 33% (4m 5s) MSE = 0.4804\n",
            "Iteration 22 | 34% (4m 17s) MSE = 0.4677\n",
            "Iteration 23 | 36% (4m 28s) MSE = 0.4690\n",
            "Iteration 24 | 38% (4m 40s) MSE = 0.4657\n",
            "Iteration 25 | 39% (4m 52s) MSE = 0.4734\n",
            "Iteration 26 | 41% (5m 4s) MSE = 0.4549\n",
            "Iteration 27 | 42% (5m 15s) MSE = 0.4690\n",
            "Iteration 28 | 44% (5m 27s) MSE = 0.4476\n",
            "Iteration 29 | 46% (5m 39s) MSE = 0.4305\n",
            "Iteration 30 | 47% (5m 50s) MSE = 0.4474\n",
            "Iteration 31 | 49% (6m 2s) MSE = 0.4472\n",
            "Iteration 32 | 50% (6m 14s) MSE = 0.4282\n",
            "Iteration 33 | 52% (6m 26s) MSE = 0.4078\n",
            "Iteration 34 | 53% (6m 37s) MSE = 0.4059\n",
            "Iteration 35 | 55% (6m 49s) MSE = 0.3964\n",
            "Iteration 36 | 57% (7m 1s) MSE = 0.4048\n",
            "Iteration 37 | 58% (7m 12s) MSE = 0.3795\n",
            "Iteration 38 | 60% (7m 24s) MSE = 0.3753\n",
            "Iteration 39 | 61% (7m 36s) MSE = 0.3712\n",
            "Iteration 40 | 63% (7m 47s) MSE = 0.3827\n",
            "Iteration 41 | 65% (7m 59s) MSE = 0.3554\n",
            "Iteration 42 | 66% (8m 11s) MSE = 0.3562\n",
            "Iteration 43 | 68% (8m 22s) MSE = 0.3559\n",
            "Iteration 44 | 69% (8m 34s) MSE = 0.3445\n",
            "Iteration 45 | 71% (8m 46s) MSE = 0.3379\n",
            "Iteration 46 | 73% (8m 57s) MSE = 0.3512\n",
            "Iteration 47 | 74% (9m 9s) MSE = 0.3394\n",
            "Iteration 48 | 76% (9m 21s) MSE = 0.3324\n",
            "Iteration 49 | 77% (9m 33s) MSE = 0.3230\n",
            "Iteration 50 | 79% (9m 44s) MSE = 0.3247\n",
            "Iteration 51 | 80% (9m 56s) MSE = 0.3223\n",
            "Iteration 52 | 82% (10m 8s) MSE = 0.3179\n",
            "Iteration 53 | 84% (10m 20s) MSE = 0.3060\n",
            "Iteration 54 | 85% (10m 31s) MSE = 0.3213\n",
            "Iteration 55 | 87% (10m 43s) MSE = 0.3154\n",
            "Iteration 56 | 88% (10m 55s) MSE = 0.2963\n",
            "Iteration 57 | 90% (11m 6s) MSE = 0.2987\n",
            "Iteration 58 | 92% (11m 18s) MSE = 0.3209\n",
            "Iteration 59 | 93% (11m 30s) MSE = 0.3028\n",
            "Iteration 60 | 95% (11m 42s) MSE = 0.2954\n",
            "Iteration 61 | 96% (11m 53s) MSE = 0.2913\n",
            "Iteration 62 | 98% (12m 5s) MSE = 0.2880\n",
            "Iteration 63 | 100% (12m 17s) MSE = 0.2839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "2Ek2Bi2P8cDS",
        "outputId": "f4747472-e823-4795-a617-f30d8e5d52a9"
      },
      "source": [
        "# Plot the learning curve\n",
        "plt.figure()\n",
        "plt.plot(all_losses, label='Training error')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f122db3e790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1eFoTOT6Ajx"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3odVoUa5rXI"
      },
      "source": [
        "test_params = {'batch_size': 64,\n",
        "          'shuffle': False,\n",
        "          'num_workers': 0}\n",
        "\n",
        "internal_test_dataset = CommonLitDataset(enc_test_X, test_Y, test_lengths)\n",
        "test_generator = torch.utils.data.DataLoader(internal_test_dataset, **test_params)\n",
        "\n",
        "\n",
        "blind_test_params = {'batch_size': 1,\n",
        "          'shuffle': False,\n",
        "          'num_workers': 0}\n",
        "\n",
        "blind_test_dataset = CommonLitDataset(enc_blind_test_X, np.zeros(enc_blind_test_X.shape), blind_test_lengths)\n",
        "blind_test_generator = torch.utils.data.DataLoader(blind_test_dataset, **blind_test_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSz_-_y_s7x3",
        "outputId": "84784611-d272-4a3d-bd6b-ae531e76eeac"
      },
      "source": [
        "# Compute the final MSE on the training set\n",
        "def compute_squared_error(generator):\n",
        "    error = nn.MSELoss(reduction='sum')\n",
        "    with torch.no_grad():\n",
        "        mse = 0.0\n",
        "        for (x, seq_len), targets_batch in generator:\n",
        "            x, targets_batch = x.to(device), targets_batch.to(device)\n",
        "\n",
        "            batch_size = x.shape[0]\n",
        "\n",
        "            output = final_model(x, seq_len)\n",
        "\n",
        "            targets_batch = torch.reshape(targets_batch, (batch_size, 1))\n",
        "\n",
        "            loss = error(output, targets_batch)\n",
        "            mse += loss.item()\n",
        "    return mse\n",
        "print('Training RMSE =', np.sqrt(compute_squared_error(training_generator) / enc_training_X.shape[0]))\n",
        "# A bit useless since we train also on this data\n",
        "print('Internal TEST RMSE =', np.sqrt(compute_squared_error(test_generator) / enc_test_X.shape[0]))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training RMSE = 0.4731130152208761\n",
            "Internal TEST RMSE = 0.6675207319861894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGPYFMTABCmK"
      },
      "source": [
        "# Compute blind test set outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wnMzcZvCl8Z",
        "outputId": "d4a98b41-9fe1-493c-b32c-5a5f509ffb36"
      },
      "source": [
        "outputs = []\n",
        "with torch.no_grad():\n",
        "    for i, ((x, seq_len), targets_batch) in enumerate(blind_test_generator):\n",
        "        excerpts_batch = x.to(device)\n",
        "\n",
        "        batch_size = excerpts_batch.shape[0]\n",
        "\n",
        "        output = final_model(excerpts_batch, seq_len)\n",
        "        id = blind_test[i, 0]\n",
        "        print(id, output.item())\n",
        "        outputs.append((id, output.item()))\n",
        "\n",
        "# Save outputs to submission.csv\n",
        "if False:\n",
        "    with open('submission.csv', 'w') as f:\n",
        "        f.write('id,target\\n')\n",
        "        for id, o in outputs:\n",
        "            f.write(id+','+o+'\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c0f722661 -1.0180059671401978\n",
            "f0953f0a5 -1.0058928728103638\n",
            "0df072751 -0.4917626976966858\n",
            "04caf4e0c -1.1692789793014526\n",
            "0e63f8bea -0.9193040728569031\n",
            "12537fe78 -0.35978007316589355\n",
            "965e592c0 -0.24307191371917725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP4t2r6es7x4"
      },
      "source": [
        " NEXT:\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        " \n",
        " \n",
        " \n",
        "    Try the nn.LSTM and nn.GRU layers\n",
        "    Combine multiple of these RNNs as a higher level network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt08ZXlQ5gvI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}