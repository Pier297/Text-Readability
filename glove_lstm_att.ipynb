{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "glove_lstm_att.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH6IfYRvrQ5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208b0910-cea6-4915-fdfb-1049bb5b8daa"
      },
      "source": [
        "!pip install torchtext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvRVLB9VrYkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db247d91-ad7b-49b5-a69b-2e6e4716f3ac"
      },
      "source": [
        "import codecs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.vocab import GloVe\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"{device} is used\")\n",
        "\n",
        "# seed everything\n",
        "seed = 1\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMmEeiSBehK3"
      },
      "source": [
        "Run one of the 2 cells below. The first one can only be run with internet access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfjj7e_Sejil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a03d0b3-0232-4fa3-eddf-670564bb0b08"
      },
      "source": [
        "embedding_dim = 300\n",
        "glove = GloVe(name=\"840B\", dim=embedding_dim)\n",
        "\n",
        "def lineToTensor(line):\n",
        "    words = re.findall(r\"[\\w']+|[.,!?;]\", line)\n",
        "    tensor = torch.tensor([glove.stoi[w] for w in words if w in glove.stoi], dtype=torch.long)\n",
        "    return glove.vectors[tensor]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.840B.300d.zip: 2.18GB [06:51, 5.29MB/s]                           \n",
            "100%|█████████▉| 2195814/2196017 [04:00<00:00, 10410.26it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe0hgig5rlfS"
      },
      "source": [
        "embedding_dim = 300\n",
        "GLOVE_EMB = 'glove.840B.300d.txt'\n",
        "embeddings_index = {}\n",
        "f = codecs.open(GLOVE_EMB, encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "    values = line.split(\" \")\n",
        "    word = value = values[0]\n",
        "    coefs = np.asarray(values[1:51], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "# Turn a line of words into the curresponding indices\n",
        "def lineToTensor(line):\n",
        "    words = re.findall(r\"[\\w']+|[.,!?;]\", line)\n",
        "    tensor = torch.tensor([embeddings_index[w] for w in words if w in embeddings_index])\n",
        "    return tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wKJzmmoequy"
      },
      "source": [
        "def pad_tensor(tensor, new_size):\n",
        "    num_pad = new_size - tensor.shape[0]\n",
        "    pad = (0, 0, 0, num_pad) # pad last dim by (0, 0) and 2nd to last by (0, num_pad)\n",
        "    return nn.functional.pad(tensor, pad, \"constant\", 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN1WYjfxTOV6"
      },
      "source": [
        "internal_train_data = pd.read_csv('internal_train.csv') # 2434 rows, 6 cols\n",
        "internal_test_data  = pd.read_csv('internal_test.csv')  #  400 rows, 6 cols\n",
        "test_data           = pd.read_csv('test.csv')           #    7 rows, 4 cols\n",
        "\n",
        "internal_train_data['encodings']    = internal_train_data.apply (lambda row: lineToTensor(row['excerpt']), axis=1)\n",
        "internal_train_data['encoding_len'] = internal_train_data.apply (lambda row: row['encodings'].shape[0], axis=1)\n",
        "internal_test_data['encodings']     = internal_test_data.apply (lambda row: lineToTensor(row['excerpt']), axis=1)\n",
        "internal_test_data['encoding_len']  = internal_test_data.apply (lambda row: row['encodings'].shape[0], axis=1)\n",
        "test_data['encodings']              = test_data.apply (lambda row: lineToTensor(row['excerpt']), axis=1)\n",
        "test_data['encoding_len']           = test_data.apply (lambda row: row['encodings'].shape[0], axis=1)\n",
        "\n",
        "# Pad tensor\n",
        "max_tensor_len = max([tensor.shape[0] for tensor in internal_train_data['encodings']])\n",
        "internal_train_data['encodings'] = internal_train_data.apply (lambda row: pad_tensor(row['encodings'], max_tensor_len), axis=1)\n",
        "internal_test_data['encodings']  = internal_test_data.apply (lambda row: pad_tensor(row['encodings'], max_tensor_len), axis=1)\n",
        "test_data['encodings']           = test_data.apply (lambda row: pad_tensor(row['encodings'], max_tensor_len), axis=1)\n",
        "\n",
        "# Split training and validation\n",
        "train_X, val_X, train_Y, val_Y = train_test_split(\n",
        "    internal_train_data[['encodings', 'encoding_len']],\n",
        "    internal_train_data['target'],\n",
        "    test_size=0.2, random_state=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl_V3rl5rvbP"
      },
      "source": [
        "class CommonLitDataset(Dataset):\n",
        "    def __init__(self, X, labels=None):\n",
        "        self.encodings = X['encodings'].to_numpy()\n",
        "        self.word_lengths = X['encoding_len'].to_numpy()\n",
        "        if labels is not None:\n",
        "            self.labels = labels.to_numpy()\n",
        "        else:\n",
        "            self.labels = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels is not None:\n",
        "            return (self.encodings[idx], self.word_lengths[idx]), torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return (self.encodings[idx], self.word_lengths[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzoFhCKT1JXy"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim, device):\n",
        "        super(Attention, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.device = device\n",
        "        self.att_weights = nn.Parameter(torch.Tensor(hidden_dim, 1), requires_grad=True)\n",
        "        stdv = 1.0 / np.sqrt(self.hidden_dim)\n",
        "        for weight in self.att_weights:\n",
        "            nn.init.uniform_(weight, -stdv, stdv)\n",
        "\n",
        "    def get_mask(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, inputs, lengths):\n",
        "        batch_size, max_len = inputs.size()[:2]\n",
        "            \n",
        "        # Apply attention layer\n",
        "        weights = torch.bmm(\n",
        "            inputs,                                                # (batch_size, max_len, hidden_dim)\n",
        "            self.att_weights.unsqueeze(0).repeat(batch_size, 1, 1) # (batch_size, hidden_dim, 1)\n",
        "        ) # (batch_size, max_len, 1)\n",
        "        attentions = torch.softmax(nn.functional.relu(weights.squeeze()), dim=-1) # (batch_size, max_len)\n",
        "\n",
        "        # Create mask based on the input lengths\n",
        "        mask = torch.ones(attentions.size(), requires_grad=False).to(self.device)\n",
        "        for i, l in enumerate(lengths):\n",
        "            if l < max_len:\n",
        "                mask[i, l:] = 0\n",
        "\n",
        "        # Apply mask and renormalize attention scores\n",
        "        masked = attentions * mask\n",
        "        sum_per_row = masked.sum(-1).unsqueeze(-1)\n",
        "        attentions = masked.div(sum_per_row)\n",
        "\n",
        "        # Get the final representations of the input\n",
        "        representations = torch.mul(inputs, attentions.unsqueeze(-1).expand_as(inputs)).sum(1).squeeze()\n",
        "\n",
        "        return representations, attentions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSPA0xOKrxE5"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, dropout, device):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.attention = Attention(hidden_dim, device)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, input_sequence, sequence_length):\n",
        "        input_sequence = self.dropout(input_sequence)\n",
        "        lstm_out, (ht, ct) = self.lstm(input_sequence)\n",
        "        att_out, _ = self.attention(lstm_out, sequence_length)\n",
        "        return self.linear(att_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_PQOgvec_e4"
      },
      "source": [
        "# Train for 1 epoch\n",
        "def train(model, optimizer, loss_function, train_loader, device):\n",
        "    model.train() # put to train mode\n",
        "    total_train_loss = 0\n",
        "    for (seq, seq_len), labels in train_loader:\n",
        "        seq, labels = seq.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(seq, seq_len)\n",
        "        loss = loss_function(y_pred, labels.unsqueeze(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "    return total_train_loss / len(train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5rIUWJdj-zR"
      },
      "source": [
        "def evaluate(model, val_loader, device):\n",
        "    total_val_loss = 0\n",
        "    model.eval() # put to eval mode\n",
        "    for (seq, seq_len), labels in val_loader:\n",
        "        with torch.no_grad():\n",
        "            seq, labels = seq.to(device), labels.to(device)\n",
        "            y_pred = model(seq, seq_len)\n",
        "            loss = loss_function(y_pred, labels.unsqueeze(-1))\n",
        "            total_val_loss += loss.item()\n",
        "    return total_val_loss / len(val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U6aWq3yGsLt"
      },
      "source": [
        "def predict(model, test_loader, device):\n",
        "    y_preds = []\n",
        "    for seq, seq_len in test_loader:\n",
        "        with torch.no_grad():\n",
        "            seq = seq.to(device)\n",
        "            preds = model(seq, seq_len)\n",
        "            y_preds.append(preds.detach().cpu().numpy())\n",
        "    return np.concatenate(y_preds).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XatcGksUr0az",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5cb817-e713-4c04-d989-4b1bbe402303"
      },
      "source": [
        "hidden_dim    = 256\n",
        "learning_rate = 0.00003\n",
        "weight_decay  = 1e-8\n",
        "dropout       = 0.2\n",
        "n_epoch       = 100\n",
        "batch_size    = 16\n",
        "\n",
        "model_loss = np.zeros((n_epoch, 2))\n",
        "\n",
        "commonlit_train = CommonLitDataset(train_X, train_Y)\n",
        "commonlit_val = CommonLitDataset(val_X, val_Y)\n",
        "train_loader = DataLoader(commonlit_train, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(commonlit_val, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Build model\n",
        "model = LSTM(embedding_dim, hidden_dim, dropout, device).to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "# Train model\n",
        "for i in range(n_epoch):\n",
        "    print(\".\", end=\"\", flush=True)\n",
        "    avg_train_loss = train(model, optimizer, loss_function, train_loader, device)\n",
        "    avg_val_loss = evaluate(model, val_loader, device)\n",
        "    model_loss[i][0] = avg_train_loss\n",
        "    model_loss[i][1] = avg_val_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...................................................................................................."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqzfKdu8BQ45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "0ae10d30-9674-4d5f-a277-865d930cf42c"
      },
      "source": [
        "# Plot the learning curve\n",
        "plt.figure()\n",
        "plt.plot(model_loss[:,0], label='Training error')\n",
        "plt.plot(model_loss[:,1], label='Val Error')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f233f3f1a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U-sSd6oyINJ",
        "outputId": "8b5c21c7-86a7-4216-bc43-b04b8ff673c9"
      },
      "source": [
        "# Train with internal train data to predict internal test set\n",
        "n_epoch = 50\n",
        "commonlit_train = CommonLitDataset(internal_train_data[['encodings', 'encoding_len']], internal_train_data['target'])\n",
        "train_loader = DataLoader(commonlit_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = LSTM(embedding_dim, hidden_dim, dropout, device).to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "for i in range(n_epoch):\n",
        "    avg_train_loss = train(model, optimizer, loss_function, train_loader, device)\n",
        "    if i % 10 == 0:\n",
        "        print('Iteration %d | Loss = %.4f' % (i, avg_train_loss))\n",
        "\n",
        "commonlit_test = CommonLitDataset(internal_test_data[['encodings', 'encoding_len']])\n",
        "test_loader = DataLoader(commonlit_test, batch_size=batch_size, shuffle=False)\n",
        "y_pred = predict(model, test_loader, device)\n",
        "print(mean_squared_error(internal_test_data['target'], y_pred, squared=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 | Loss = 1.4160\n",
            "Iteration 10 | Loss = 0.4699\n",
            "Iteration 20 | Loss = 0.3989\n",
            "Iteration 30 | Loss = 0.3505\n",
            "Iteration 40 | Loss = 0.3404\n",
            "0.6541691908851036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PXkdj3NHUyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8f7a73-827a-4cd2-85f9-c2834455fbc8"
      },
      "source": [
        "# Train with full dataset\n",
        "n_epoch = 50\n",
        "train_data = pd.concat([internal_train_data, internal_test_data])\n",
        "commonlit_train = CommonLitDataset(train_data[['encodings', 'encoding_len']], train_data['target'])\n",
        "train_loader = DataLoader(commonlit_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = LSTM(embedding_dim, hidden_dim, dropout, device).to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "for i in range(n_epoch):\n",
        "    avg_train_loss = train(model, optimizer, loss_function, train_loader, device)\n",
        "    if i % 10 == 0:\n",
        "        print('Iteration %d | Loss = %.4f' % (i, avg_train_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 | Loss = 1.3818\n",
            "Iteration 10 | Loss = 0.4348\n",
            "Iteration 20 | Loss = 0.3895\n",
            "Iteration 30 | Loss = 0.3522\n",
            "Iteration 40 | Loss = 0.3439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsSz-NfdGxEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1e2d62-5c2c-4bfd-dd18-0ccd9340447a"
      },
      "source": [
        "# Predict blind test set\n",
        "commonlit_test = CommonLitDataset(test_data[['encodings', 'encoding_len']])\n",
        "test_loader = DataLoader(commonlit_test, batch_size=batch_size, shuffle=False)\n",
        "test_data['target'] = predict(model, test_loader, device)\n",
        "submission = test_data[['id', 'target']]\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(submission)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          id    target\n",
            "0  c0f722661 -1.444140\n",
            "1  f0953f0a5 -0.345342\n",
            "2  0df072751 -0.318216\n",
            "3  04caf4e0c -2.357437\n",
            "4  0e63f8bea -2.305949\n",
            "5  12537fe78 -1.385960\n",
            "6  965e592c0  0.295750\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}